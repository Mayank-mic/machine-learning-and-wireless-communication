# -*- coding: utf-8 -*-
"""Copy of IDP.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15AOJ-ReLne_KKtJ5tJW-W-jR1Zt6dGJT
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive

import numpy as np
a=np.fromfile('/content/sample1', dtype=np.complex64)

print(a)

print(a[:20])

complex_samples = np.array(a[::2] + 1j * a[1::2])

import pandas as pd
pd.DataFrame(a).to_csv('sample.csv')

import pandas as pd

b=np.fromfile('/content/sample2distorted1', dtype=np.complex64)

import numpy as np
from scipy.fft import fft
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC

# Compute FFT of both original and collected signals
original_signal_fft = np.abs(fft(a[20000:250000]))
collected_signal_fft = np.abs(fft(b[20000:250000]))

print(original_signal_fft)

import matplotlib.pyplot as plt
plt.figure(figsize=(12,7))
plt.subplot(1,2,1)
plt.plot(original_signal_fft[20000:250000])

print(collected_signal_fft)
plt.subplot(1,2,2)
plt.plot(collected_signal_fft[20000:250000])
plt.show()

print(collected_signal_fft.argmax(axis=0))
print(original_signal_fft.argmax(axis=0))

b1=np.fromfile('/content/sample2distorted1.2', dtype=np.complex64)

# Compute FFT of both original and collected signals
collected_signal_fft = np.abs(fft(b1[30000:250000]))

print(original_signal_fft)

import matplotlib.pyplot as plt
plt.figure(figsize=(12,7))
plt.subplot(1,2,1)
plt.plot(original_signal_fft[20000:250000])

print(collected_signal_fft)
plt.subplot(1,2,2)
plt.plot(collected_signal_fft[30000:250000])
plt.show()

summer=np.sum(np.abs(b1))
print(summer)

print(collected_signal_fft.argmax(axis=0))
print(original_signal_fft.argmax(axis=0))

max_index = np.argmax(np.abs(collected_signal_fft))
max_index

gesture2=np.fromfile('/content/sample2distorted2', dtype=np.complex64)

# Compute FFT of both original and collected signals

collected_signal_fft = np.abs(fft(gesture2[20000:250000]))

print(original_signal_fft)

import matplotlib.pyplot as plt
plt.figure(figsize=(12,7))
plt.subplot(1,2,1)
plt.plot(original_signal_fft[20000:250000])

print(collected_signal_fft)
plt.subplot(1,2,2)
plt.plot(collected_signal_fft[20000:250000])
plt.show()

print(collected_signal_fft.argmax(axis=0))
print(original_signal_fft.argmax(axis=0))

gesture22=np.fromfile('/content/sample2distorted2.2', dtype=np.complex64)

collected_signal_fft = np.abs(fft(gesture22[20000:250000]))

print(original_signal_fft)

import matplotlib.pyplot as plt
plt.figure(figsize=(12,7))
plt.subplot(1,2,1)
plt.plot(original_signal_fft[20000:250000])

print(collected_signal_fft)
plt.subplot(1,2,2)
plt.plot(collected_signal_fft[20000:250000])
plt.show()
print(collected_signal_fft.argmax(axis=0))
print(original_signal_fft.argmax(axis=0))



gesture4=np.fromfile('/content/sample2distorted4', dtype=np.complex64)

collected_signal_fft = np.abs(fft(gesture4[20000:250000]))

print(original_signal_fft)

import matplotlib.pyplot as plt
plt.figure(figsize=(12,7))
plt.subplot(1,2,1)
plt.plot(original_signal_fft[20000:250000])

print(collected_signal_fft)
plt.subplot(1,2,2)
plt.plot(collected_signal_fft[20000:250000])
plt.show()
print(collected_signal_fft.argmax(axis=0))
print(original_signal_fft.argmax(axis=0))

orig_fft = np.fft.fft(a)

# calculate FFT of distorted IQ samples
dist_fft = np.fft.fft(b)

freq_axis = np.fft.fftfreq(len(orig_fft))

# find the index of the maximum value in the FFT of the distorted signal
max_index = np.argmax(np.abs(dist_fft))

# calculate the frequency offset
freq_offset = freq_axis[max_index]

print('Frequency offset:', freq_offset)

# calculate the speed of light in meters per second
c = 299792458

# calculate the Doppler shift in Hertz
doppler_shift = freq_offset * c / (2 * np.pi * 2.4e9)

print('Doppler shift:', doppler_shift)

orig_fft = np.fft.fft(a)

# calculate FFT of distorted IQ samples
dist_fft = np.fft.fft(b1)

freq_axis = np.fft.fftfreq(len(orig_fft))

# find the index of the maximum value in the FFT of the distorted signal
max_index = np.argmax(np.abs(dist_fft))

# calculate the frequency offset
freq_offset = freq_axis[max_index]

print('Frequency offset:', freq_offset)

# calculate the speed of light in meters per second
c = 299792458

# calculate the Doppler shift in Hertz
doppler_shift = freq_offset * c / (2 * np.pi * 2.4e9)

print('Doppler shift:', doppler_shift)

orig_fft = np.fft.fft(a)

# calculate FFT of distorted IQ samples
dist_fft = np.fft.fft(gesture22)

freq_axis = np.fft.fftfreq(len(orig_fft))

# find the index of the maximum value in the FFT of the distorted signal
max_index = np.argmax(np.abs(dist_fft))

# calculate the frequency offset
freq_offset = freq_axis[max_index]

print('Frequency offset:', freq_offset)

# calculate the speed of light in meters per second
c = 299792458

# calculate the Doppler shift in Hertz
doppler_shift = freq_offset * c / (2 * np.pi * 2.4e9)

print('Doppler shift:', doppler_shift)

orig_fft = np.fft.fft(a)

# calculate FFT of distorted IQ samples
dist_fft = np.fft.fft(gesture4)

freq_axis = np.fft.fftfreq(len(orig_fft))

# find the index of the maximum value in the FFT of the distorted signal
max_index = np.argmax(np.abs(dist_fft))

# calculate the frequency offset
freq_offset = freq_axis[max_index]

print('Frequency offset:', freq_offset)

# calculate the speed of light in meters per second
c = 299792458

# calculate the Doppler shift in Hertz
doppler_shift = freq_offset * c / (2 * np.pi * 2.4e9)

print('Doppler shift:', doppler_shift)

signal_org2=np.fromfile('/content/sample original 2', dtype=np.complex64)

collected_signal_fft = np.abs(fft(signal_org2[20000:250000]))

print(original_signal_fft)

import matplotlib.pyplot as plt
plt.figure(figsize=(12,7))
plt.subplot(1,2,1)
plt.plot(original_signal_fft[20000:250000])

print(collected_signal_fft)
plt.subplot(1,2,2)
plt.plot(collected_signal_fft[20000:250000])
plt.show()
print(collected_signal_fft.argmax(axis=0))
print(original_signal_fft.argmax(axis=0))

"""#AMPLITUDE DETECTION"""

signal_org_AMP2=np.fromfile('/content/drive/MyDrive/IDP Sample folder/sample original 3 amplitude', dtype=np.complex64)

len(signal_org_AMP2)

sum1=np.sum(np.abs(signal_org_AMP2[300000:330000]))
print(sum1)

signal_dist_amp1=np.fromfile('/content/drive/MyDrive/IDP Sample folder/sample original 3 amplitude2', dtype=np.complex64)
sum2=np.sum(np.abs(signal_dist_amp1[300000:330000]))
print(sum2)

signal_dist1_1=np.fromfile('/content/drive/MyDrive/IDP Sample folder/sample distorted amplitude   gesture1.1', dtype=np.complex64)
sum4=np.sum(np.abs(signal_dist1_1[300000:330000]))
print(sum4)

signal_dist1_2=np.fromfile('/content/drive/MyDrive/IDP Sample folder/sample distorted amplitude   gesture1.2', dtype=np.complex64)
sum5=np.sum(np.abs(signal_dist1_2[300000:330000]))
print(sum5)

signal_dist2=np.fromfile('/content/drive/MyDrive/IDP Sample folder/sample distorted amplitude   gesture2', dtype=np.complex64)
sum6=np.sum(np.abs(signal_dist2[300000:330000]))
print(sum6)

signal_dist2_1=np.fromfile('/content/drive/MyDrive/IDP Sample folder/sample distorted amplitude   gesture2.1', dtype=np.complex64)
sum7=np.sum(np.abs(signal_dist2_1[300000:330000]))
print(sum7)

# import random
# df=pd.DataFrame()
# df.colums=['sum','label']

# signal_dist2_2=np.fromfile('/content/drive/MyDrive/IDP Sample folder/Gesturesample1.4', dtype=np.complex64)
# for i in range(10000):
#   a=random.randint(100000,len(signal_dist2_2))
#   sum8=np.sum(np.abs(signal_dist2_2[a:a+30000]))
#   # Define the new row
#   new_row = pd.DataFrame({'sum': [sum8], 'label': [1]})

# # Append the new row to the data frame
#   if(sum8<=6500 and sum8>3000):
#     df = pd.concat([df,new_row], ignore_index=True)

from google.colab import drive
drive.mount('/content/drive')

# Import Module
import os
import numpy as np
import pandas as pd
import random
df=pd.DataFrame()
df.colums=['sum','mean','min','max','label']
# Folder Path
path = "/content/drive/MyDrive/IDP Sample folder"
  
# Change the directory
os.chdir(path)
  
# Read text File
  
  
def read_text_file(file_path):
    with open(file_path, 'r') as f:
        print(f.read())
  
  
# iterate through all file
for file in os.listdir(path):
    # Check whether file is in text format or not
        file_path = f"{path}/{file}"
  
        # call read text file function
       # read_text_file(file_path)
        if(file=='.ipynb_checkpoints'):
          continue
        signal_new=np.fromfile(file_path, dtype=np.complex64)
        # summ_o=np.sum(np.abs(signal_new[300000:330000]))
        r=0
        if(file.endswith('_0')):
          r=5000
          l=0
        elif(file.endswith('_1')):
          r=500
          l=1
        for i in range(r):
          a=random.randint(100000,len(signal_new))
          arr=np.abs(signal_new[a:a+30000])
          sum=np.sum(arr)
          mini=min(arr)
          maxi=max(arr)
          # Define the new row
          new_row = pd.DataFrame({'sum': [sum],'mean':[sum/30000],'min':[mini],'max':[maxi], 'label': [l]})

        # Append the new row to the data frame
          if(sum>3000):
            df = pd.concat([df,new_row], ignore_index=True)
        # print(file)
        # print(summ_o)

for i in range(5000):
  a=random.uniform(6000,8000)
  mini=random.uniform(0,0.2)
  maxi=random.uniform(0.1,0.5)
  # Define the new row
  new_row = pd.DataFrame({'sum': [a],'mean':[a/30000],'min':[mini],'max':[maxi], 'label': [2]})
  df = pd.concat([df,new_row], ignore_index=True)



df=df.sample(frac=1).reset_index(drop=True)
df

train_labels=df['label']
train_data=df.drop(['mean','min','max','label'],axis=1)

# split into train test sets using stratify 
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(train_data,train_labels, test_size=0.2, random_state=1, stratify=train_labels)

train_labels.value_counts()

x_train.iloc[0].shape

# Using kernel linear
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score
from sklearn.metrics import accuracy_score
rbf_svc = SVC(kernel='linear')
rbf_svc.fit(x_train,y_train)
y_pred=rbf_svc.predict(x_test)
accuracy_score(y_test, y_pred)

send=rbf_svc.predict(pd.DataFrame([7043]))

send[0]

import pickle
# save the model to disk
filename = 'finalized_model.pkl'
pickle.dump(rbf_svc, open(filename, 'wb'))
 
# some time later...
 
# load the model from disk
# loaded_model = pickle.load(open(filename, 'rb'))

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

# true labels
y_true = [0, 1, 1, 0, 1, 0, 0, 1]

# predicted labels
y_pred = [1, 1, 0, 0, 1, 0, 1, 1]

# calculate confusion matrix
cm = confusion_matrix(y_true, y_pred)

# plot confusion matrix
sns.heatmap(cm, annot=True, cmap='Blues')
plt.xlabel('Predicted Labels')
plt.ylabel('True Labels')
plt.show()

import tensorflow as tf
from tensorflow import keras
from tensorflow.keras.callbacks import LearningRateScheduler
import matplotlib.pyplot as plt

# load the saved model
model = keras.models.load_model('my_model.h5')

# define learning rate schedule
def lr_schedule(epoch):
    """
    Learning rate schedule function.
    """
    lr = 1e-3
    if epoch > 50:
        lr *= 0.5e-3
    elif epoch > 20:
        lr *= 1e-3
    elif epoch > 10:
        lr *= 1e-2
    elif epoch > 5:
        lr *= 1e-1
    print('Learning rate: ', lr)
    return lr

# create a learning rate schedule callback
lr_scheduler = LearningRateScheduler(lr_schedule)

# compile the model
model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# train the model
history = model.fit(X_train, y_train, epochs=100, validation_data=(X_val, y_val), callbacks=[lr_scheduler])

# plot the learning rate and loss
plt.semilogx(history.history["lr"], history.history["loss"])
plt.axis([1e-5, 1e-1, 0, 1])
plt.xlabel("Learning rate")
plt.ylabel("Loss")
plt.show()